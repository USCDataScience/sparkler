name: dev-deploy

on:
  release:
    types:
      - created

env:
  PKG_NAME: sparkler-app
  PKG_VERSION: N/A
  PKG_PATH: sparkler-core
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  DATABRICKS_HOST: https://dbc-6b70bbcd-c212.cloud.databricks.com
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TEST_TOKEN }}
  DATABRICKS_RELEASE_PATH: dbfs:/FileStore/release

jobs:
  standalone:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Set up JDK 8
        uses: actions/setup-java@v2
        with:
          java-version: '8'
          distribution: adopt

      - name: Install Databricks CLI
        run: pip install databricks-cli

      - name: Create the release folder
        run: databricks fs mkdirs ${{ env.DATABRICKS_RELEASE_PATH }}

      - name: Set package version
        run: echo "PKG_VERSION=$(grep version version.sbt | cut -d'"' -f2)" >> $GITHUB_ENV
        working-directory: ${{ env.PKG_PATH }}

      - name: Build "Standalone" package
        run: sbt package assembly -Dsparkprovided=false -Dmaven.javadoc.skip=true
        working-directory: ${{ env.PKG_PATH }}

      - name: Remove library jars
        run: rm -r build/${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}
        working-directory: ${{ env.PKG_PATH }}

      - name: Zip the Sparkler build
        run: zip -r ${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}.zip *
        working-directory: ${{ env.PKG_PATH }}/build

      - name: Deploy "Standalone" to Databricks
        run: databricks fs cp ${{ env.SRC_ZIP }} ${{ env.DEST_ZIP }}
        working-directory: ${{ env.PKG_PATH }}/build
        env:
          SRC_ZIP: ${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}.zip
          DEST_ZIP: ${{ env.DATABRICKS_RELEASE_PATH }}/${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}-$GITHUB_SHA.zip

  submit:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Set up JDK 8
        uses: actions/setup-java@v2
        with:
          java-version: '8'
          distribution: adopt

      - name: Install Databricks CLI
        run: pip install databricks-cli

      - name: Create the release folder
        run: databricks fs mkdirs ${{ env.DATABRICKS_RELEASE_PATH }}

      - name: Set package version
        run: echo "PKG_VERSION=$(grep version version.sbt | cut -d'"' -f2)" >> $GITHUB_ENV
        working-directory: ${{ env.PKG_PATH }}

      - name: Create the plugins folder
        run: databricks fs mkdirs ${{ env.DATABRICKS_RELEASE_PATH }}/plugins/plugins-${{ env.PKG_VERSION }}

      - name: Build "Submit" package
        run: sbt clean package assembly -Dsparkprovided=true -Dmaven.javadoc.skip=true
        working-directory: ${{ env.PKG_PATH }}

      - name: Deploy "Submit" to Databricks
        run: databricks fs cp ${{ env.SRC_JAR }} ${{ env.DEST_JAR }}
        working-directory: ${{ env.PKG_PATH }}
        env:
          SRC_JAR: build/${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}.jar
          DEST_JAR: ${{ env.DATABRICKS_RELEASE_PATH }}/${{ env.PKG_NAME }}-${{ env.PKG_VERSION }}-$GITHUB_SHA.jar

      - name: Deploy plugins to Databricks
        run: databricks fs cp --overwrite --recursive ${{ env.SRC_JARS }} ${{ env.DEST_DIR }}
        working-directory: ${{ env.PKG_PATH }}
        env:
          SRC_JARS: build/plugins/
          DEST_DIR: ${{ env.DATABRICKS_RELEASE_PATH }}/plugins/plugins-${{ env.PKG_VERSION }}/
