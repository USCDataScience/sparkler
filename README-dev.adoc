= Sparkler Build From Source
Thamme Gowda, 2023-03-28
:source-highlighter: rouge
:icons: font


== Setup 

Install SDKMAN

[source,bash]
----
curl -s "https://get.sdkman.io" | bash
# open new shell session
  
sdk install java 11.0.18-ms   # We need this version
sdk install scala 2.12.15
sdk install sbt 1.6.1


# making sure these versions are active in enviroment
sdk use java 11.0.18-ms
sdk use scala 2.12.15
sdk use sbt 1.6.1
----

== Build Sparkler



[source,bash]
----
git clone git@github.com:USCDataScience/sparkler.git
cd sparkler 
git checkout tg/refresh    # use this branch

sbt clean compile package assembly
build/bin/sparkler.sh  # this should print "inject" "crawl" "dump" help message
----


=== Running First Crawl


.Setup Elasticsearch (ES)
----
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.17.0-linux-x86_64.tar.gz
tar xvf elasticsearch-7.17.0-*.tar.gz

# start ES as daemon
elasticsearch-7.17.0/bin/elasticsearch -d -p pid
----

Check if http://localhost:9200/ is up (If you see a JSON doc, it means ES is working)


.Run Crawl
----
build/bin/sparkler.sh inject -id myid -su 'http://www.bbc.com/news'
build/bin/sparkler.sh crawl -id myid -tn 100 -i 2


----

You should see docs updated in ES index at  `http://localhost:9200/crawldb/_search?pretty=true&q=*:*`
In addition to ES index, crawl data is also stored under `crawl-data/` directory, since `fetcher.persist.content.location` setting is configured to have that path.
To change any settings, edit `buidld/conf/sparkler-default.yaml` file.  The instructions in this page is tested with https://github.com/USCDataScience/sparkler/blob/59dc833c49ea0efd5f199b558b92275af535b13f/conf/sparkler-default.yaml[this version of config]

